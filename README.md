# graduate-project
AI를 활용한 운전자의 발성 데이터를 분석하여 스트레스 수준을 평가하고, 이를 통해 운전 적합 여부를 판별하는 시스템

---

# **보고서: 음성 감정 인식 모델 성능 비교**

## **1. 서론**
음성 데이터를 기반으로 감정을 분류하는 것은 감정 컴퓨팅의 중요한 과제입니다. 이 보고서에서는 음성 데이터의 감정을 인식하기 위해 **CNN**, **RNN**, **Transformer** 모델을 사용하여 성능을 비교 분석합니다. 모델 성능은 **정확도(Accuracy)**, **정밀도(Precision)**, **재현율(Recall)**, **F1 Score**를 통해 평가되었습니다. 또한 **학습 손실**, **검증 손실**, **혼동 행렬**을 시각화하여 각 모델의 성능을 시각적으로 분석했습니다.

## **2. 실험 설정**

### **2.1 데이터셋**
- **TESS 데이터셋**을 사용하였으며, 총 7개의 감정(angry, disgust, fear, happy, neutral, ps, sad)을 **스트레스 상태(Stressed)** 와 **비스트레스 상태(NotStressed)** 로 이진 분류했습니다. 
  - **Stressed**: angry, disgust, fear, sad
  - **NotStressed**: happy, neutral, ps
- 음성 데이터를 **MFCC(Mel-Frequency Cepstral Coefficients)**로 변환하여 모델 학습에 필요한 음향 특징을 추출했습니다.

### **2.2 모델 아키텍처**
- **CNN**: 3개의 **Convolution** 레이어와 **Dropout**을 사용하여 음성 데이터를 처리했습니다.
- **RNN**: 4개의 **LSTM** 층과 **Adaptive Average Pooling**으로 음성 데이터를 처리했습니다.
- **Transformer**: 4개의 **트랜스포머 인코더** 레이어와 **Average Pooling**으로 음성 데이터를 처리했습니다.

### **2.3 손실 함수 및 옵티마이저**
- **손실 함수**: **BCEWithLogitsLoss**를 사용하여 이진 분류 문제를 처리했습니다.
- **옵티마이저**: **Adam**을 사용하여 모델의 파라미터를 학습했습니다.
- 모든 모델은 **100 epoch** 동안 학습되었으며, **학습 데이터**와 **검증 데이터**에 대한 성능을 평가했습니다.

## **3. 결과 및 분석**

### **3.1 CNN 모델**
- **Accuracy**: 0.796
- **Precision**: [0.713, 0.989]
- **Recall**: [0.993, 0.6]
- **F1 Score**: [0.83, 0.747]

![CNN 결과](file-oQpDSgYXwOFJqCkbTfFzvagl)

**CNN 모델**은 검증 손실에서 약간의 변동을 보였으며, 이는 **과적합** 가능성을 시사합니다. **테스트 정확도는 79.6%**로 나타났습니다. **혼동 행렬**을 보면 비스트레스를 스트레스로 **오분류**하는 경향이 보였으며, 이는 모델이 비스트레스 데이터를 스트레스 데이터보다 잘 분류했음을 의미합니다.

---

### **3.2 RNN 모델**
- **Accuracy**: 0.983
- **Precision**: [0.99, 0.977]
- **Recall**: [0.977, 0.99]
- **F1 Score**: [0.983, 0.983]

![RNN 결과](file-zT6YcCihM8ynij3oddIYGsoO)

**RNN 모델**은 모든 모델 중 **가장 높은 성능**을 보였습니다. 학습 손실과 검증 손실이 꾸준히 감소했으며, **정확도는 98.3%**에 도달했습니다. **혼동 행렬**에서도 스트레스와 비스트레스 데이터를 거의 완벽하게 구분하였으며, 두 클래스 모두 **높은 재현율**과 **정밀도**를 기록했습니다.

---

### **3.3 Transformer 모델**
- **Accuracy**: 0.651
- **Precision**: [0.731, 0.613]
- **Recall**: [0.48, 0.823]
- **F1 Score**: [0.579, 0.703]

![Transformer 결과](file-uPxTTX73aVyM98R1pdxMc3Se)

**Transformer 모델**은 상대적으로 **낮은 성능**을 보였습니다. 학습과 검증 손실이 일관되게 감소했으나, **정확도는 65.1%**로 낮았습니다. **혼동 행렬**을 보면 스트레스를 비스트레스로 **오분류**하는 경향이 강하게 나타났습니다. 이는 트랜스포머 모델이 **시계열 데이터**를 학습하는 데 적합하지 않을 수 있음을 시사합니다.

---

## **4. 결론**

이번 실험에서 **RNN 모델**이 음성 감정 인식 문제에서 **가장 높은 성능**을 기록하였습니다. 이는 음성 데이터의 **시계열적 특성**을 가장 잘 반영할 수 있는 모델로 **RNN**이 적합하다는 결론을 도출할 수 있습니다.

- **CNN 모델**은 상대적으로 괜찮은 성능을 보였으나, 과적합 문제가 발생할 가능성이 있었습니다.
- **Transformer 모델**은 음성 데이터에 적합하지 않아 비교적 낮은 성능을 보였습니다.

향후 연구에서는 **더 복잡한 RNN 구조**(예: **GRU** 또는 **Bi-LSTM**)를 활용하거나, 데이터 증강 기법을 적용하여 음성 감정 인식 성능을 더욱 향상시킬 수 있는 방안을 탐구할 수 있습니다.

---

이 보고서는 가독성을 높이기 위해 깔끔한 레이아웃과 각 모델의 성능을 강조하는 방식으로 작성되었습니다. 필요한 경우 추가적으로 모델의 세부 하이퍼파라미터 설정이나 데이터셋의 특성을 추가 설명할 수 있습니다.
